model_list:
  # Tier 1 - Fast Models (for simple queries, FAQs, greetings)
  - model_name: tier1/llama-3.2-3b
    litellm_params:
      model: together_ai/Meta-Llama-3.2-3B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
      max_tokens: 2048
      temperature: 0.7
      rpm: 3000
      timeout: 30
    model_info:
      tier: 1
      description: "Fast model for simple queries"
      cost_per_token: 0.00001
  
  - model_name: tier1/gemini-flash
    litellm_params:
      model: gemini/gemini-1.5-flash
      api_key: os.environ/GEMINI_API_KEY
      max_tokens: 2048
      temperature: 0.7
      rpm: 3000
      timeout: 30
    model_info:
      tier: 1
      description: "Alternative fast model"
      cost_per_token: 0.00001

  # Tier 2 - Balanced Models (for product queries, basic support)
  - model_name: tier2/claude-haiku
    litellm_params:
      model: claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 4096
      temperature: 0.5
      rpm: 1000
      timeout: 60
    model_info:
      tier: 2
      description: "Balanced model for standard queries"
      cost_per_token: 0.00025
      
  - model_name: tier2/gpt-3.5-turbo
    litellm_params:
      model: gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096
      temperature: 0.5
      rpm: 1000
      timeout: 60
    model_info:
      tier: 2
      description: "Alternative balanced model"
      cost_per_token: 0.0002

  # Tier 3 - Advanced Models (for technical support, complex queries)
  - model_name: tier3/claude-sonnet
    litellm_params:
      model: claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
      temperature: 0.3
      rpm: 500
      timeout: 120
    model_info:
      tier: 3
      description: "Advanced model for complex queries"
      cost_per_token: 0.003
      
  - model_name: tier3/gpt-4
    litellm_params:
      model: gpt-4
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 8192
      temperature: 0.3
      rpm: 500
      timeout: 120
    model_info:
      tier: 3
      description: "Alternative advanced model"
      cost_per_token: 0.003

  # Tier 4 - Premium Models (for sales negotiation, high-value leads)
  - model_name: tier4/claude-opus
    litellm_params:
      model: claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 16384
      temperature: 0.2
      rpm: 200
      timeout: 180
    model_info:
      tier: 4
      description: "Premium model for critical interactions"
      cost_per_token: 0.015
      
  - model_name: tier4/gpt-4-turbo
    litellm_params:
      model: gpt-4-turbo-preview
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 16384
      temperature: 0.2
      rpm: 200
      timeout: 180
    model_info:
      tier: 4
      description: "Alternative premium model"
      cost_per_token: 0.01

# Fallback settings
litellm_settings:
  # Retry logic
  num_retries: 3
  request_timeout: 600
  retry_after: 5
  
  # Fallback strategy
  fallbacks:
    tier1/llama-3.2-3b: ["tier1/gemini-flash"]
    tier2/claude-haiku: ["tier2/gpt-3.5-turbo", "tier1/llama-3.2-3b"]
    tier3/claude-sonnet: ["tier3/gpt-4", "tier2/claude-haiku"]
    tier4/claude-opus: ["tier4/gpt-4-turbo", "tier3/claude-sonnet"]
  
  # Context window fallbacks
  context_window_fallbacks:
    - {"tier4/claude-opus": ["tier3/claude-sonnet"]}
    - {"tier3/claude-sonnet": ["tier2/claude-haiku"]}
  
  # Success callback
  success_callback: ["prometheus", "custom_callback"]
  
  # Cache settings
  cache: true
  cache_params:
    type: "redis"
    host: os.environ/REDIS_HOST
    port: os.environ/REDIS_PORT
    password: os.environ/REDIS_PASSWORD
    ttl: 3600
  
  # Rate limiting
  max_parallel_requests: 50
  
  # Alerting
  alerting:
    - provider: "prometheus"
      environment_variables:
        PROMETHEUS_URL: os.environ/PROMETHEUS_URL
  
  # General settings
  drop_params: true
  set_verbose: false

# Router settings for intelligent model selection
router_settings:
  routing_strategy: "cost-optimized-routing"
  
  # Model selection rules
  model_rules:
    - name: "simple_queries"
      conditions:
        intent: ["greeting", "faq", "simple_info"]
        max_tokens: 500
      preferred_models: ["tier1/llama-3.2-3b", "tier1/gemini-flash"]
      
    - name: "product_queries"
      conditions:
        intent: ["product_query", "support_basic"]
        max_tokens: 2000
      preferred_models: ["tier2/claude-haiku", "tier2/gpt-3.5-turbo"]
      
    - name: "technical_support"
      conditions:
        intent: ["technical_support", "complex_query"]
        max_tokens: 4000
      preferred_models: ["tier3/claude-sonnet", "tier3/gpt-4"]
      
    - name: "high_value_interactions"
      conditions:
        intent: ["sales_negotiation", "high_value_lead"]
        user_value: "high"
      preferred_models: ["tier4/claude-opus", "tier4/gpt-4-turbo"]
      
    - name: "vip_customers"
      conditions:
        user_tier: "vip"
      min_model_tier: 2

# Environment variables required
environment_variables:
  # API Keys
  ANTHROPIC_API_KEY: ""
  OPENAI_API_KEY: ""
  TOGETHER_API_KEY: ""
  GEMINI_API_KEY: ""
  
  # Redis
  REDIS_HOST: "localhost"
  REDIS_PORT: "6379"
  REDIS_PASSWORD: ""
  
  # Monitoring
  PROMETHEUS_URL: "http://prometheus:9090"
  
  # General
  LITELLM_MASTER_KEY: ""
  LITELLM_DATABASE_URL: ""
  LITELLM_LOG_LEVEL: "INFO"
